{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6730fecf",
   "metadata": {},
   "source": [
    "# Assignment 2 \n",
    "### \\<Weiyou Liu> \\<A1872800>\n",
    "### \\<Hengyi Ma> \\<A1875198>\n",
    "### \\<name3> \\<id3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2aac6",
   "metadata": {},
   "source": [
    "## A. Tasks as specified for your team structure\n",
    "\n",
    "**One headings for each task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c729de",
   "metadata": {},
   "source": [
    "#### 1. Load date and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de57e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import chardet   \n",
    "import spacy\n",
    "import stanza\n",
    "import neuralcoref\n",
    "import random\n",
    "import nltk\n",
    "import torch\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from torch.nn.functional import softmax\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663f5a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected encoding: utf-8\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/homes/Adam/NLP/ASM2/news_dataset.csv\"\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    rawdata = file.read()\n",
    "\n",
    "result = chardet.detect(rawdata)\n",
    "encoding = result['encoding']\n",
    "\n",
    "print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "if encoding:\n",
    "    df = pd.read_csv(file_path, encoding=encoding)\n",
    "else:\n",
    "    print(\"Failed to detect encoding. Consider specifying encoding manually.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6355c6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>topic</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>18456</td>\n",
       "      <td>Victor Mather</td>\n",
       "      <td>13/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>At least six members of the Super   New Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>18308</td>\n",
       "      <td>Ken Belson</td>\n",
       "      <td>8/02/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>sports</td>\n",
       "      <td>HOUSTON  ?   There was the game on the field, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>17636</td>\n",
       "      <td>Ron Lieber</td>\n",
       "      <td>14/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>When Wells Fargo announced its quarterly earni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>17938</td>\n",
       "      <td>Dale Russakoff</td>\n",
       "      <td>29/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>politics</td>\n",
       "      <td>When Indira Islas was in third grade at Centen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>18070</td>\n",
       "      <td>Laurie Goodstein</td>\n",
       "      <td>30/01/2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>crime</td>\n",
       "      <td>Over the past decade, Christians in the United...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            author        date  year month     topic  \\\n",
       "993  18456     Victor Mather  13/02/2017  2017     2  politics   \n",
       "859  18308        Ken Belson   8/02/2017  2017     2    sports   \n",
       "298  17636        Ron Lieber  14/01/2017  2017     1  business   \n",
       "553  17938    Dale Russakoff  29/01/2017  2017     1  politics   \n",
       "672  18070  Laurie Goodstein  30/01/2017  2017     1     crime   \n",
       "\n",
       "                                               article  \n",
       "993  At least six members of the Super   New Englan...  \n",
       "859  HOUSTON  ?   There was the game on the field, ...  \n",
       "298  When Wells Fargo announced its quarterly earni...  \n",
       "553  When Indira Islas was in third grade at Centen...  \n",
       "672  Over the past decade, Christians in the United...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.sample(n=100, random_state=np.random.seed(0))\n",
    "sample_df.head()\n",
    "# Randomly select 100 samples to speed up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12b8acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Assuming the following are placeholders for previously defined preprocessing and entity extraction functions\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and stem the words\n",
    "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975810a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text column\n",
    "sample_df['cleaned_article'] = sample_df['article'].apply(clean_text)\n",
    "\n",
    "# Vectorize the processed text\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(sample_df['cleaned_article'])\n",
    "# tfidf_matrix is the processed numerical data, which can be used for subsequent NLP tasks\n",
    "\n",
    "# Apply function to extract entities from each article\n",
    "sample_df['entities'] = sample_df['article'].apply(extract_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b151ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_to_index = {doc_id: index for index, doc_id in enumerate(sample_df.index)}\n",
    "# Because the index is random, we need a dictionary to map doc_id to index\n",
    "\n",
    "inverted_index = defaultdict(set)\n",
    "for index, row in sample_df.iterrows():\n",
    "    for entity in row['entities']:\n",
    "        inverted_index[entity[0]].add(index)  # entity[0] is the text of the entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b01511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 14:27:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 30.0MB/s]                    \n",
      "2024-04-12 14:27:48 INFO: Downloaded file to /home/vscode/stanza_resources/resources.json\n",
      "2024-04-12 14:27:50 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| coref     | ontonotes_electra-large   |\n",
      "| depparse  | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-04-12 14:27:50 WARNING: GPU requested, but is not available!\n",
      "2024-04-12 14:27:50 INFO: Using device: cpu\n",
      "2024-04-12 14:27:50 INFO: Loading: tokenize\n",
      "2024-04-12 14:27:50 INFO: Loading: mwt\n",
      "2024-04-12 14:27:50 INFO: Loading: pos\n",
      "2024-04-12 14:27:50 INFO: Loading: lemma\n",
      "2024-04-12 14:27:50 INFO: Loading: coref\n",
      "2024-04-12 14:27:54 INFO: Loading: depparse\n",
      "2024-04-12 14:27:54 INFO: Loading: ner\n",
      "2024-04-12 14:27:54 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse,ner,coref', use_gpu=True)\n",
    "\n",
    "# Define a function to resolve coreferences in a text\n",
    "def coref_resolve(text, nlp):\n",
    "    try:\n",
    "        # Process the text with the NLP pipeline\n",
    "        doc = nlp(text)\n",
    "        # Initialize an empty list to store representative mentions\n",
    "        representative_mentions = []\n",
    "        # Iterate over sentences, tokens, and words in the document\n",
    "        for sentence in doc.sentences:\n",
    "            for token in sentence.tokens:\n",
    "                for word in token.words:\n",
    "                    # If a word has coreference chains\n",
    "                    if hasattr(word, 'coref_chains'):\n",
    "                        # Check each chain to see if it is a representative mention\n",
    "                        for chain in word.coref_chains:\n",
    "                            if chain.is_representative:\n",
    "                                # If it is, add the word text to the list\n",
    "                                representative_mentions.append(word.text)\n",
    "                                break\n",
    "        # Return the list of representative mentions\n",
    "        return representative_mentions\n",
    "    except IndexError:\n",
    "        # Print an error message if there is an issue with processing the text\n",
    "        print(\"Error processing text:\", text)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d3e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing text: When Indira Islas was in third grade at Centennial Arts Academy, a public elementary school in Gainesville, Ga. she decided it was time to get serious. It was 2006, and she was in the lowest reading group in her class. She had been in that group since arriving two years earlier, speaking no English, in Gainesville, a city of 38, 000 just northeast of Atlanta?s booming outer suburbs. But being at the bottom went against everything she believed about herself. ?I wanted to be with the smart kids,? she recalls. Starting the year before, in second grade, she read every volume of the ?Magic Tree House? books in her   library, a series about two ordinary siblings who climb into their backyard treehouse and   to Pompeii, the Wild West, the ice age, feudal Japan and beyond. ?I absolutely loved them,? she says. ?It was like going on adventures all over the world. ? It was also the opposite of her own life. Indira left Mexico for the United States at age 6 with her parents and two younger sisters. Her mother cleaned houses when she wasn?t caring for the children  ?   there would eventually be seven of them  ?   and her father worked in construction, and there was no money for   lessons or soccer clubs, let alone traveling. ?I?d hear about trips and experiences of my white friends, and I remember thinking: I?ll never go to the beach or Disney World for spring break,? Indira says. Her parents told her that education was all that mattered, and she had to spend all her free time inside, reading and writing. ?I tell my children this country is a blessing to all the people living here,? her mother told me. ?If you have the opportunity to be good, it?s very important to take it. ? Indira took this advice to heart. By the time she was in fifth grade, her reading skills had improved so much that she tested into the top reading group. By middle school, she consistently got A?s, which qualified her for a celebratory school trip every time report cards came out. ?They rewarded us by taking us skating or bowling,? she says. ?I felt like I was so smart, just getting the chance to go out for the whole school day with friends. That?s when I said: ?I can make it. ??u2009? Indira began to throw herself into everything. At recess, she played soccer and basketball, competing so fiercely that everyone took notice. Boys usually picked other boys for their teams, and white kids tended to favor other white kids. But everyone started picking Indira. In middle school, she was on the track team, running   races. Her coach was stunned by her determination. In meets, even when she won her event, she scolded herself unless she broke her previous record. After practices ended, she would keep running. ?I wanted to think,? she says. ?I?d stay after practice and run and run and run. ? Indira remembers understanding vaguely that it wasn?t just poverty that set her and her family apart. Her parents had been doctors in Mexico. She admired pictures in their dresser drawer of the two of them in their 20s standing together, tall and proud in their white coats  ?   before they all fled the violence of drug gangs who were then taking over their home state, Guerrero. When she asked her parents why they were no longer doctors, they explained it was because they were not American citizens. It didn?t make sense to Indira. Why would her father have shed that beautiful crisp white coat for the fraying pants and shirts he now wore? Soon after Indira turned 13, in 2011, she was riding home from track practice with her mother when another car sideswiped the family?s Ford Expedition. The other driver, who was at fault, insisted on calling the police, according to Indira and a lawyer who assisted the family. Indira pleaded not to involve the police, explaining that her mother did not have a driver?s license because she was not an American citizen. (In Georgia and most other states, undocumented immigrants cannot obtain driver?s licenses.) But the driver said she needed a police report to get insurance to cover the damage to her car. A police officer arrived and asked for Indira?s mother?s license. When she said she did not have one  ?   a state crime  ?   she was told to get out of the car. Indira got out, too. She remembers two of her younger siblings sleeping in the back, one in a booster seat, one in a car seat. Two elders from the church they attended arrived to ask for mercy. She has seven children, they told the officer. He responded that he was simply enforcing the law. Indira?s mother turned to her and began to cry. ?Indira, I don?t know what is going to happen,? she said. ?They?re going to take me. ? Indira remembers remaining strangely calm. ?When she was being handcuffed, I said: ?Mom, everything is going to be O. K.??u2009? Indira?s mother was held in Gainesville?s Hall County jail for three days, but that wasn?t the most frightening part for the family. Hall is one of four counties in Georgia that have a formal agreement to report arrests of undocumented immigrants to the Department of Homeland Security, which means that infractions as minor as a   bulb above a license plate can spiral into deportation proceedings. Indira?s mother says that her charge of driving without a license ultimately led to a referral to immigration court and a deportation order instructing her to leave the country within 30 days. She stayed, slipping into the shadows. Every day since, Indira says, she and her siblings have feared that their mother would be deported. It would take only one more traffic stop. ?That woke me up,? Indira says. ?Until then, I thought the world was happy. ? In fact, she now realized, it was only American citizens who seemed truly happy. ?It must feel pretty good, I guess, to not have to worry about whether your family could be taken away any day. ? Indira has wanted to be a doctor for almost as long as she can remember. When she was 10, her family was shopping for groceries at Sam?s Club, and she spotted a large book about human anatomy. She became so excited about it that her parents bought it for her birthday, even though it was well above her reading level  ?   and their price range. She began working her way through it, mesmerized, and when she got stuck, her mother would explain whatever had stumped her. She was determined to go to college and medical school and fulfill her parents? interrupted dream. In her junior year, Indira began researching college options. She would be a strong applicant. She was consistently at or near the top of her class she was on the   track and soccer teams she volunteered over 1, 000 hours a year at the local hospital, a record in the history of the   program and she led her school?s chapter of the Hispanic Organization Promoting Education (HOPE) which encouraged Latino students  ?   who made up just over half the district?s population  ?   to stay in school and graduate. She was distressed to discover that Georgia barred undocumented immigrants from attending its top public universities and charged them    tuition at all others  ?   triple the rate for citizen residents. She then turned to researching financial aid and learned that Congress barred her from accessing federal Pell grants, loans, scholarships and   jobs  ?   the most common forms of assistance for   students. At first, she greeted this as just another set of obstacles to surmount, but as time went on, she began to despair. She would retreat to the classroom of her science teacher, Teresa Leach, who had become her mentor, in need of encouragement. ?There were a couple of times when I just cried to her because I was tired,? she said. ?I questioned myself if it was all worth the effort. ? All the while, Indira told me, she held onto her religious conviction that God had a plan, and that she must respect it. At a college fair attended by representatives of numerous Georgia colleges, she asked admissions officers what kind of help was available for undocumented students. No one had any to offer her. She switched her focus to private colleges and was admitted to Atlanta?s Agnes Scott, which she says awarded her $20, 000 annually in financial aid, less than half of what she needed. She researched   private scholarships and found two for undocumented students, but she was selected for neither. She was awarded seven small scholarships, which totaled $10, 000, enough to go to a nearby public commuter college for only one semester at the    tuition rate. Last May, Indira attended her graduation ceremony at Gainesville High School, but she had nowhere to go next. In every picture from that day, she wears a wide smile, but she was in pain inside, particularly when she caught a glimpse of her mother in the crowd, looking distraught. Unable to bring herself to celebrate with friends, she went home to be with her family. Days later, a friend told her about a philanthropic organization called TheDream. US, which was offering undocumented students full   scholarships to Delaware State University or Eastern Connecticut State University. The application was demanding, and only 76 students would be chosen. She poured herself into the essays, spending hours composing them alongside an English teacher, Cindy Lloyd. She applied to Delaware State, a historically black college in Dover, five hours closer to home than Eastern Connecticut. In late June, she received an email from TheDream. US. ?I saw ?Congratulations,??u2009? she remembers, ?and I read no more. ? In late August, Indira made the   drive with her parents from Gainesville to Delaware State in unusual silence. She was thinking hard about each of her six younger siblings, wondering how they would fare without her. Over breakfast at a Cracker Barrel in South Carolina, when her mother pressed her about how she was feeling, she talked only of her concerns about not being at home to help everyone. When she arrived on campus  ?   a flat expanse of grassy courtyards and buildings amid strip malls, auto dealers and chain restaurants just beyond Dover?s historic capital area  ?   she found 33 other ?opportunity scholars,? just as worried and hopeful as she was. All of them were assigned to a dorm about a quarter of a mile from the D. S. U. campus, a former Sheraton hotel acquired a few years earlier by the university as part of an expansion. They bonded instantly, traveling as a posse from classes to the library to the cafeteria, often ending up together late at night in the dorm lobby or in a lounge that had been a large hotel suite on the second floor. In their first month on campus, the opportunity scholars were invited to a welcoming ceremony in the school?s Martin Luther King Jr. Student Center with Gov. Jack Markell the Democratic senator Tom Carper Donald Graham, a founder of TheDream. US and D. S. U. ?s president, Harry Williams. ?This is not just an opportunity for you it is an opportunity for the state of Delaware,? Markell told them. ?It is sad to see your own home state reject such talent and potential. ? He pronounced himself ?thrilled that you?re here. ? It was the first time many of the students could recall being welcomed anywhere. ?We felt rejection our whole lives from our own states,? Indira said. ?We were here only three weeks, and we already met the governor and the senator. It felt like saying ?Haha!? to Georgia. ? Of the 34 opportunity scholars enrolled at D. S. U. 28 are from Mexico and one each is from Ecuador, El Salvador, Peru, Gabon, Gambia and Trinidad and Tobago. Their families are a composite portrait of the economic forces that have drawn undocumented immigrants to the nation?s small towns and metropolitan heartland. Their parents work in poultry plants, on factory lines, in warehouses, on construction sites, in restaurants they clean and paint houses and schools, tend gardens. ?They make everything look perfect for the tourists,? Yulma Lopez, who left Mexico at age 3, said of her parents? work for a landscaping company in Charleston, S. C. Almost all their parents work illegally, but many pay income taxes, having obtained federal   numbers. And some, including Indira?s father, have secured temporary federal permission to work and drive lawfully. While most of the students are 18 or 19, typical for college freshmen, some have worked for years in hopes of one day saving enough for college. Olivia Bekale, who is 27 and grew up in Baton Rouge, arrived in Louisiana from Gabon as a child. She graduated from high school in 2008 with a 3. 9 G. P. A. from the Louisiana School for Math, Science and the Arts, a prestigious   boarding school for top achievers. Unable to afford college, she cycled from one   position to the next  ?   server at the Melting Pot, a fondue restaurant retail sales consultant for Sprint   agent for Marriott pharmacy tech for Walgreens. Olivia, who had wanted to be a doctor since an aunt died of AIDS when she was 5, had been out of high school for eight years when she learned of the opportunity scholarship she applied immediately. All but one of the students were enrolled in the Deferred Action for Childhood Arrivals program, also known as DACA. Created in 2012 by an   executive action, DACA allowed teenagers and young adults who came to the United States illegally as children with their parents to register with the government and in turn receive a   renewable protection against deportation, along with work permits and Social Security numbers. Most of the students, like Indira, signed up at age 15, as soon as they were eligible. With DACA, Indira, who is now 18, was able to get a driver?s license and a job at a Publix supermarket when she was in high school, working 20 hours a week as a cashier and bagger. Being able to work and drive legally, free of the fears her mother faced, and fitting in with her classmates, Indira says, was ?living the American dream. ? With her income from Publix, she even was able to get braces for her teeth. The starting point for all of their dreams was education, and the quest for it has been central to the experience of undocumented young people since long before Indira and her classmates were born. In the late 1970s, when undocumented immigrants had yet to move in large numbers beyond border states, Texas passed a law authorizing local school districts to ban them from public schools or charge them tuition. In a landmark decision in Plyler v. Doe in 1982, a narrowly divided Supreme Court struck down the law, finding that undocumented children had a constitutional right to free    public education. The opinion blamed a dysfunctional immigration system for creating the crisis by failing to keep out undocumented immigrants or provide them a path to citizenship. ?Already disadvantaged as a result of poverty, lack of   ability and undeniable racial prejudices, these children, without an education, will become permanently locked into the lowest socioeconomic class,? Justice William Brennan wrote for the majority, quoting the   opinion. The case also introduced the argument that undocumented children were legally blameless, unlike their parents: ?The classification at issue deprives a group of children of the opportunity for education afforded all other children simply because they have been assigned a legal status due to a violation of law by their parents,? Justice Lewis Powell wrote in a concurring opinion. Undocumented children poured into the nation?s schools over the next generation, and as they reached college age, they coalesced into a movement, advocating access to higher education as well as full citizenship. In 2001, they began calling themselves Dreamers, now an estimated 2. 1 million young immigrants who have grown up as Americans in almost every way except for their passports. The name came from the Dream Act (Development, Relief and Education for Alien Minors) introduced in Congress in 2001 by Senator Richard Durbin, a Democrat from Illinois, and Senator Orrin Hatch, a Republican from Utah, and for which activists fought for over a decade. The measure, which would have put undocumented children on a path to citizenship, never passed, but the vast network of Dreamers became a compelling political force. In 2001, hundreds of them turned out to testify in Texas in favor of legislation to allow undocumented residents to pay   college tuition if they graduated from Texas high schools and lived in the state for three years. ?Something magical happened when those kids told their stories,? says the former Texas state representative Rick Noriega, a Democrat who sponsored the bill. ?It was a humanizing of a very real issue dealing with children?s dreams and hopes. Every heart on that committee was touched, Republicans and Democrats. ? The legislation passed both houses almost unanimously and was signed by Rick Perry, then governor of Texas and now President Donald Trump?s pick for energy secretary. Texas became the first state, followed quickly by California, to allow Dreamers to pay   tuition. Today, 21 states charge Dreamers the same tuition as legal residents, including six carried by Trump  ?   Florida, Kansas, Nebraska, Oklahoma, Utah and Texas. In many of those states, however, the   issue has turned politically treacherous. In Texas, efforts to repeal the tuition law come closer to passing every year, and Noriega says there is no chance the original measure would pass today. The leading national opponents of   tuition for Dreamers include the Republican senator Jeff Sessions, Trump?s choice for attorney general, and the secretary of state of Kansas, Kris Kobach, a Republican who was a leader of Trump?s transition team on immigration. Each argues that students who are in the United States illegally should not get a public benefit in any state that is denied to a citizen from another state. In other words, if Dreamers pay   tuition in Texas, citizen students next door in Arkansas and Oklahoma  ?   or Massachusetts, for that matter  ?   should have the same right. ?How much sense does that make, to have people here illegally, and they have more benefits than those who are here legally?? Sessions asked in a Senate floor statement. Kobach used the same argument to bring   lawsuits against   tuition for Dreamers in Kansas and California. Judges found no legal basis for the claims and dismissed the cases. The larger debate over how to treat an estimated 11 million immigrants who came here illegally has been at a stalemate for decades, with advocates seeking a ?path to citizenship? for   families who have been in the country for years and opponents denouncing ?amnesty? for people who broke the law to enter the country. Amid hardening resistance in Congress to immigration reform, Dreamers brought pressure on Obama  ?   including   and hunger strikes at his 2012 campaign offices  ?   to use his executive power to create DACA. The program, announced on June 15, 2012, the 30th anniversary of the Supreme Court?s Plyler decision, proved transformative for Dreamers. They have entered college, taken    jobs, received driver?s licenses, bought cars. They now fly on planes, passing effortlessly through airport security. They still lack legal immigration status, but no longer are they exactly undocumented. ?DACAmented,? many have called themselves. Even in states where they pay   tuition, Dreamers still struggle to afford college because they are disproportionately   and have no access to federal financial aid. Fewer than 10 percent of Dreamers who graduate from high school enroll in college. At a time when college graduates earn 70 percent more than those without degrees, these numbers conjure the 1982 warning by the Supreme Court that undocumented children could become a permanent underclass. In response, a handful of philanthropies have adopted the cause of sending students with DACA status to college. The biggest of these, TheDream. US, has raised $90 million to eventually finance 4, 000 students at public colleges, with significant contributions from Donald Graham, former publisher and chief executive of The Washington Post, and his family Mark Zuckerberg and Priscilla Chan Bill and Melinda Gates the   executive William Ackman and Michael Bloomberg, among others. (I was a reporter at The Washington Post from 1980 to 2008.) In 2014, TheDream. US began offering Dreamers full scholarships in states that charge them   tuition. Last year, in partnership with Delaware and Connecticut, the organization created the   program for students from the other 29 states, financed by $41 million in philanthropy from Graham and his family and two anonymous donors. The governors of Delaware and Connecticut agreed to charge roughly   tuition rates for the 34 scholars at Delaware State and the 42 at Eastern Connecticut State  ?   a total of $80, 000 per student for tuition, room and board for four years. In an effort to   political opposition, Graham says, the philanthropy works only with schools, like Delaware State and Eastern Connecticut State, that have excess capacity, so that undocumented students are not displacing citizens. And private donors pay all expenses, so that no state dollars are spent. Still, when The Delaware State News ran an article in September about the D. S. U. opportunity scholars, the online comments complained that undocumented immigrants, not citizens, were benefiting. ?Trump isn?t perfect, but I will vote for him because he puts Americans FIRST,? wrote a reader named John Huff of Magnolia, Del. ?There are plenty of kids who are citizens who have the same dream and should come first. ? And as news of the scholarship spread on the Delaware campus this fall, a number of   students told Dreamers that they resented that their own families had to go into debt for a portion of their education costs while the DACA students got full scholarships. By then, Trump had mobilized   anger in large swaths of the country, having kicked off his campaign criticizing Mexican immigrants  ?   ?They?re bringing drugs. They?re bringing crime. They?re rapists?  ?   and vowing to build a wall on the border to keep them out. In stump speeches, he promised to deport all 11 million undocumented immigrants and, in his first 100 days in office, to terminate DACA, labeling it ?illegal amnesty. ? Both vows became instant applause lines. Indira declared her major in biological sciences at the beginning of the semester and started a demanding   curriculum with six classes, including biology and chemistry, both requiring labs. Her parents had insisted she not take a job, in order to devote herself to education, freeing up four hours a night that she had spent working in high school. With that extra time, she found the academic challenges manageable. Much harder was living apart from her   family for the first time in her life. Her mother texted her daily. ?Good morning, hija,? she wrote one recent morning, using the Spanish word for daughter. ?May God bless you today in school. Please be kind to everyone. ? That night, over FaceTime, Indira talked with two of her younger sisters, who like her were born in Mexico and are undocumented. One, a junior in high school, is already on a quest for college scholarships. She and Indira came up with potential essay ideas and discussed her r?sum?. Then Indira helped the other, a freshman who is the smartest of all the family?s children, Indira says, with physics homework. On weekends, she FaceTimes with her four youngest siblings  ?   a sixth grader, a fourth grader, a third grader and a first grader  ?   all of whom were born in Georgia and are citizens. Separation from family, from home, even from Mexican food made most of the opportunity scholars profoundly lonely. Estephany Martinez, a petite   major with long black hair, couldn?t stop thinking about her sisters in the first weeks. ?Whenever we came home from school, all four sisters would sit in the living room and do our homework and talk and watch TV,? she recalled wistfully of her life in Winder, Ga. In Delaware, ?I didn?t have anybody that cared for me. I didn?t have anyone to come home to. ? In early September, she summoned all the scholars to a gathering in the dorm?s   lounge. ?All right, you guys, we?re going to be here for each other,? she said. ?That part of our lives  ?   being undocumented  ?   is critical to who we are. We have to share our stories. ? Everyone crowded in, sitting on the sofa, spilling onto the floor, sitting shoulder to shoulder on counters that once were part of a kitchenette, sprawling into one another?s space. Carlos Gonzales of Manteo, N. C. a lanky and cheerful marketing major whose mother is a restaurant cook, broke down crying when he recalled the violence that drove his family from Mexico City. He, his mother and his younger sister moved to North Carolina when he was 7. It was his mother who encouraged him, beginning in elementary school, to reach for college. ?I don?t want you to live the life we?re living now,? she told him. In high school, he was an honor student and varsity wrestler and runner, working nights and weekends at McDonald?s in his Outer Banks town. When he received the email telling him he was an opportunity scholar, he said: ?I hugged my mom and cried for two hours. The only reason I stopped was I had to go to work. ? Indira told the harrowing story that led to her own family?s departure from Mexico. In 2004, when she was 6, three masked gunmen broke into their home, which housed her parents? clinic, and robbed them of everything  ?   money, jewelry, a new computer, a television, cameras and medications. They filed a report with the police, they said, who didn?t investigate, in deference to cartels then taking over Guerrero, now the most violent state in Mexico. An uncle of her father?s already had been killed. In subsequent years, a cousin of her mother?s, a veterinarian, was kidnapped and never found. Two nephews disappeared. Her mother?s sister has been kidnapped twice  ?   most recently this past November  ?   and returned only after her family paid steep ransoms. Weeks after the robbery, Indira?s family of five arrived in the United States on a tourist visa that her father procured a month earlier in hopes of taking everyone to Disney World. Instead, they went to Gainesville, where her father?s brother worked in construction  ?   one of thousands of Mexican workers who flocked to the north Georgia community in the last 25 years, swelling the Hispanic population to more than 40 percent in 2013 from 8 percent in 1990. Indira said her parents are certain they would have been killed had they stayed. They decided to forfeit their careers for their family?s safety. ?I no longer saw my future, but I saw my children?s future,? her father said to me. Antonio Patino, a   major who is a lifeguard and plays bass and guitar in his spare time, told the group about riding with his family in their car in 2015 in Lawrenceville, Ga. when a police officer pulled them over, though none of them understood why. His father, who is undocumented and processes returns for a local manufacturer, was driving but did not have a license. Antonio and his mother, younger sister and brother all watched in terror as his father was handcuffed, placed in a police cruiser and driven off to jail. As it turned out, he was released the next day after paying a fine of more than $800 and was not referred to immigration court for further proceedings, but the incident shook Antonio?s sense of belonging in America. ?I felt like I got slapped in the face just for living, trying to be a normal person in this beautiful country,? he said. ?It feels like a hole inside me. ? He said he now found himself gripped with fears for his parents? safety at random moments during his days at D. S. U. It is as if he has swapped roles with his mother and father. ?Like I?m now the parent and they?re the child, and I?m worried for them,? he told me. ?Not being there, all these   swarm into my mind. What if out of nowhere they get pulled over again?? Calling them and hearing their voices usually comforts him. But after one such call, he said: ?I went outside, and I had to cry a little. I was feeling like I couldn?t help them. ? A number of students shared the enormous sacrifices they had seen their parents make for them. Juan Chavez, 23, who grew up in Plymouth, Ind. and worked for five years after high school, told of his mother suffering a breakdown after her divorce from his father. He saw it as a response to the crushing instability of their lives, moving from one home to another in search of shelter. ?She?s the strongest person I?ll ever know,? he said. ?She?s my role model. My father figure as well as my mother. ? He continued: ?I felt so helpless to make things better. I decided almost right then I?ll go to college and medical school if it takes me the rest of my life. ? He is now a psychology and   major, intending to become a psychiatrist. On and on the students went until almost 3 a. m. the common threads in their stories drawing them closer. It was the first time most of them had talked openly about being undocumented, but instead of feeling exposed, they felt safer. Until then, Antonio had gone out of his way to avoid conversations with   at D. S. U. about his scholarship, not wanting to have to explain that he got it because he was undocumented. The next day, though, he fell into conversation with a student who asked him how he happened to come all the way from Georgia to D. S. U. and he said without hesitation: ?I got a scholarship. ? ?What for?? ?I?m undocumented,? Antonio said, surprised at how comfortable this felt. ?O. K. man, that?s cool,? the student said. After their long night talking, the scholars also better understood what had propelled them all for as long as they could remember. Throughout high school, the opportunity scholars watched undocumented friends and siblings give up and drop out, shamed and beaten down by public scorn over illegal immigration and the   options awaiting even those who excelled in high school. But they kept on striving, steeled to the insults, positioning themselves for a breakthrough they couldn?t yet see. Now this all made sense. ?This pain  ?   it pushes us,? Estephany said. ?It?s motivation. It has made me who I am. It makes me go through every day. ? ?Now we know what drives us,? Indira said. One morning in   at 9:50 a. m. 10 minutes before Indira?s   class was scheduled to start, she and two other opportunity scholars were already ensconced in the three center   seats, notebooks, pens and textbooks at the ready. Indira was wearing a Harvard sweatshirt that a classmate bought for her when their   A. P.  class visited Boston. (Indira couldn?t afford to go.) ?I?m going to get there one day,? she said with a confident smile. Most of the other students didn?t arrive until class was about to begin  ?   or later  ?   and there was little competition for the front rows. A similar scene unfolded that morning in the ultramodern science center, in   class, where Antonio and Jose Reyes Rios, another   major, sat front and center with an   classmate named Hanqaamo Lintisio, who is from Maryland and has a track scholarship. The three had formed a study group and tutored one another so effectively that they all scored above 100 on the midterm. (They nailed the bonus question.) Theirs were the only A?s in the class. The Dreamers gather daily at a long Formica table in a D. S. U. cafeteria for food and conversation. At lunch, Carla Moreno propped her English composition textbook, ?Patterns for College Writing,? against a napkin holder, securing it with an apple. She paged through a chapter while eating her salad and chili dog. ?It?s just a quiz,? she said, ?but I want to keep my A. ? ?I deal with a lot of students, and I feel like the Dreamers are at a different level,? says Kevin Noriega, the adviser for their scholarships. ?They?re saying, ?I?ve got to make this happen because it?s my only option. ??u2009? Of the 488 scholars funded by TheDream. US who began college in 2014, 94 percent remain enrolled after their sophomore year research shows that only 66 percent of   college students nationally return after one year. ?This is a   population with retention rates like Harvard?s,? Donald Graham says. Because beneficiaries of TheDream. US have full rides, they avoid a common problem faced by other disadvantaged students: running short of money for costs not covered by Pell grants or other forms of aid. One night in October before a biology exam, Indira went to the D. S. U. athletic center for a workout to relieve stress. She was armed with a stack of homemade flash cards and her iPhone, on which she had downloaded discussions of test topics from various websites. While pounding ou\n"
     ]
    }
   ],
   "source": [
    "sample_df['coref_chains'] = sample_df['article'].apply(lambda x: coref_resolve(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2cbd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_entities_to_corefs(entities, coref_chains):\n",
    "    entity_coref_map = {}\n",
    "    for entity in entities:\n",
    "        entity_text = entity[0]  #entities are tuples of (text, type)\n",
    "        entity_coref_map[entity_text] = []\n",
    "        for coref in coref_chains:\n",
    "            if entity_text in coref:\n",
    "                entity_coref_map[entity_text].append(coref)\n",
    "    return entity_coref_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c14952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this function row-wise, assuming 'coref_chains' and 'entities' are available for each row\n",
    "sample_df['entity_coref_map'] = sample_df.apply(lambda row: map_entities_to_corefs(row['entities'], row['coref_chains']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7efe179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query_text):\n",
    "    # 对查询进行预处理和实体识别\n",
    "    cleaned_query = clean_text(query_text)\n",
    "    query_vector = vectorizer.transform([cleaned_query])\n",
    "    query_entities = extract_entities(query_text)\n",
    "    \n",
    "    # 基于实体和共指信息查找文档\n",
    "    docs_based_on_content = set()\n",
    "    for entity_text, _ in query_entities:\n",
    "        # 使用倒排索引直接根据实体查找文档\n",
    "        docs_based_on_content.update(inverted_index.get(entity_text, []))\n",
    "        \n",
    "        # 使用共指信息查找相关文档\n",
    "        for doc_id in sample_df.index:\n",
    "            coref_map = sample_df.at[doc_id, 'entity_coref_map']\n",
    "            for coref_entity, mentions in coref_map.items():\n",
    "                if entity_text == coref_entity or entity_text in mentions:\n",
    "                    docs_based_on_content.add(doc_id)\n",
    "                    break  # 如果找到匹配，就跳出循环\n",
    "\n",
    "    # 直接使用找到的文档进行评分和排序\n",
    "    if docs_based_on_content:\n",
    "        docs_indices = [doc_id_to_index[doc_id] for doc_id in docs_based_on_content if doc_id in doc_id_to_index]\n",
    "        docs_tfidf = tfidf_matrix[docs_indices]\n",
    "        cos_similarities = cosine_similarity(query_vector, docs_tfidf).flatten()\n",
    "        \n",
    "        scored_docs = sorted(zip(docs_based_on_content, cos_similarities), key=lambda x: x[1], reverse=True)\n",
    "        ranked_docs = [doc[0] for doc in scored_docs]\n",
    "        \n",
    "        return ranked_docs\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8198e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found documents: [494]\n"
     ]
    }
   ],
   "source": [
    "# 对索引的功能进行测试\n",
    "\n",
    "query_text = input(\"Enter your query text: \")\n",
    "\n",
    "\n",
    "ranked_docs = search_documents(query_text)\n",
    "if ranked_docs:\n",
    "    print(f\"Found documents: {ranked_docs}\")\n",
    "else:\n",
    "    print(\"No documents found or query format incorrect.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "888048da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    # 使用全局变量bert_tokenizer和bert_model处理文本\n",
    "    inputs = bert_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    outputs = bert_model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings.detach().numpy()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def find_top_n_relevant_contents(question, article_content, top_n=5, window_size=5):\n",
    "    # 使用spaCy进行句子分割\n",
    "    doc = nlp(article_content)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # 获取句子文本并去除首尾空白\n",
    "\n",
    "    # 其余的逻辑与之前相同\n",
    "    paragraph_embeddings = []\n",
    "    for i in range(len(sentences) - window_size + 1):\n",
    "        window_sentences = ' '.join(sentences[i:i+window_size])\n",
    "        window_embedding = get_bert_embeddings([window_sentences])[0]  # 假设get_bert_embeddings返回numpy数组\n",
    "        paragraph_embeddings.append(window_embedding)\n",
    "\n",
    "    paragraph_embeddings = np.array(paragraph_embeddings)\n",
    "    question_embedding = get_bert_embeddings([question])[0]\n",
    "\n",
    "    # 计算相似度并找到最相关的窗口\n",
    "    similarities = cosine_similarity([question_embedding], paragraph_embeddings).flatten()\n",
    "    top_n_indices = np.argsort(similarities)[-top_n:][::-1]\n",
    "    top_n_contents = [(' '.join(sentences[i:i+window_size]), similarities[i]) for i in top_n_indices]\n",
    "\n",
    "    return top_n_contents\n",
    "\n",
    "\n",
    "def encode_question_and_context(question, context):\n",
    "    # 使用全局变量qa_tokenizer对问题和上下文进行编码\n",
    "    return qa_tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "def find_answer(question, context, top_k=3):\n",
    "    inputs = encode_question_and_context(question, context)\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    outputs = qa_model(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "\n",
    "    # 计算开始和结束分数的softmax分布\n",
    "    start_probs = softmax(answer_start_scores, dim=-1)\n",
    "    end_probs = softmax(answer_end_scores, dim=-1)\n",
    "\n",
    "    # 提取排名前top_k的开始和结束位置\n",
    "    start_topk = torch.topk(start_probs, top_k)\n",
    "    end_topk = torch.topk(end_probs, top_k)\n",
    "\n",
    "    top_answers = []\n",
    "    for start_index, start_score in zip(start_topk.indices[0], start_topk.values[0]):\n",
    "        for end_index, end_score in zip(end_topk.indices[0], end_topk.values[0]):\n",
    "            # 确保结束位置在开始位置之后\n",
    "            if end_index >= start_index:\n",
    "                answer = qa_tokenizer.convert_tokens_to_string(qa_tokenizer.convert_ids_to_tokens(input_ids[start_index:end_index + 1]))\n",
    "                score = (start_score.item() + end_score.item()) / 2  # 简单地取平均分数作为置信度\n",
    "                top_answers.append((answer, score))\n",
    "                break  # 只添加每个开始位置的最佳结束位置\n",
    "\n",
    "    # 根据置信度分数降序排列答案\n",
    "    top_answers = sorted(top_answers, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return top_answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02697316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_single(predicted, truth):\n",
    "    # 如果truth是字符串，将其转换为只包含一个元素的列表\n",
    "    if isinstance(truth, str):\n",
    "        truth = [truth]\n",
    "    # 将所有真实答案合并为一个大的token集合，以处理答案列表的情况\n",
    "    truth_tokens = set(token.lower() for answer in truth for token in answer.split())\n",
    "\n",
    "    pred_tokens = set(predicted.lower().split())\n",
    "    common_tokens = pred_tokens.intersection(truth_tokens)\n",
    "    if not common_tokens:\n",
    "        return 0.0\n",
    "    precision = len(common_tokens) / len(pred_tokens)\n",
    "    recall = len(common_tokens) / len(truth_tokens)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def compute_mrr(predicted_article_ids, truth_article_ids):\n",
    "    if not isinstance(predicted_article_ids, list):\n",
    "        predicted_article_ids = [predicted_article_ids]\n",
    "    rank = 0\n",
    "    for i, predicted_id in enumerate(predicted_article_ids, start=1):\n",
    "        if predicted_id in truth_article_ids:\n",
    "            rank = 1 / i\n",
    "            break\n",
    "    return rank\n",
    "\n",
    "def compute_map(predicted_article_ids, truth_article_ids):\n",
    "    if not isinstance(predicted_article_ids, list):\n",
    "        predicted_article_ids = [predicted_article_ids]\n",
    "    avg_precisions = []\n",
    "    for i, predicted_id in enumerate(predicted_article_ids, start=1):\n",
    "        if predicted_id in truth_article_ids:\n",
    "            relevant_count = sum(pred_id in truth_article_ids for pred_id in predicted_article_ids[:i])\n",
    "            precision_at_i = relevant_count / i\n",
    "            avg_precisions.append(precision_at_i)\n",
    "    return np.mean(avg_precisions) if avg_precisions else 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lcs_length(x, y):\n",
    "    \"\"\"计算两个序列的最长公共子序列（LCS）的长度\"\"\"\n",
    "    if not x or not y:\n",
    "        return 0\n",
    "    dp = [[0] * (len(y) + 1) for _ in range(len(x) + 1)]\n",
    "    for i in range(1, len(x) + 1):\n",
    "        for j in range(1, len(y) + 1):\n",
    "            if x[i - 1] == y[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])\n",
    "    return dp[-1][-1]\n",
    "\n",
    "def compute_rouge_l_multi(predicted_answers, truths):\n",
    "    def compute_rouge_l(predicted, truth):\n",
    "        \"\"\"计算单个预测答案与单个真实答案之间的ROUGE-L分数。\"\"\"\n",
    "        lcs = lcs_length(predicted, truth)\n",
    "        if lcs == 0:\n",
    "            return 0\n",
    "        precision = lcs / len(predicted)\n",
    "        recall = lcs / len(truth)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        return f1\n",
    "    \n",
    "    rouge_l_scores = []\n",
    "    for predicted in predicted_answers:  # 直接处理每个预测答案文本\n",
    "        # 计算当前预测答案与每个真实答案之间的ROUGE-L分数，并取最大值\n",
    "        scores_for_this_answer = [compute_rouge_l(predicted, truth) for truth in truths]\n",
    "        rouge_l_scores.append(max(scores_for_this_answer))\n",
    "    \n",
    "    return np.mean(rouge_l_scores) if rouge_l_scores else 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "916b2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_answers = {\n",
    "    \"fact_based\": [\n",
    "        {\n",
    "            \"question\": \"What organization began compiling opposition research on Donald Trump in September 2015?\",\n",
    "            \"answer\": \"Fusion GPS\",\n",
    "            \"article_id\": 230\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What Netflix series is a reboot of a Norman Lear sitcom that discusses class divide?\",\n",
    "            \"answer\": \"One Day at a Time\",\n",
    "            \"article_id\": 77\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Who was the American ambassador to the United Nations who issued a warning to allies and rivals in her first remarks?\",\n",
    "            \"answer\": \"Nikki R. Haley\",\n",
    "            \"article_id\": 614\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"In which year did Xi Jinping come to power in China?\",\n",
    "            \"answer\": [\"2012\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the title of Yang Jisheng's book about the Cultural Revolution?\",\n",
    "            \"answer\": [\"The World Turned Upside Down\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What year did the Cultural Revolution begin?\",\n",
    "            \"answer\": [\"1966\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Which state is Monticello located in?\",\n",
    "            \"answer\": \"Iowa\",\n",
    "            \"article_id\": 261\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the name of Yang Jisheng's other book about the famine caused by the Great Leap Forward?\",\n",
    "            \"answer\": [\"Tombstone\"],\n",
    "            \"article_id\": 494\n",
    "        },       \n",
    "        {\n",
    "            \"question\": \" What is the name of the film starring Matthew McConaughey that involves the mining industry and is set in the 1980s?\",\n",
    "            \"answer\": [\"Gold\"],\n",
    "            \"article_id\": 601\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Which Taiwanese official provided updates on the Liaoning's transit?\",\n",
    "            \"answer\": \"Alex Huang, the president's spokesman\",\n",
    "            \"article_id\": 239\n",
    "        }\n",
    "    ],\n",
    "    \"explanation_based\": [\n",
    "        {\n",
    "            \"question\": \"What did Bonnie S. Glaser say about the potential response from the Trump administration to China's actions?\",\n",
    "            \"answer\": \"Bonnie S. Glaser suggested that if the Trump administration views this as a test of U.S. resolve, they are likely to push back pretty forcefully.\",\n",
    "            \"article_id\": 239\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How does 'One Day at a Time' reflect the issue of class divide in its narrative?\",\n",
    "            \"answer\": \"The show reflects the class divide by showcasing a family that is closer to the lower side of the economic spectrum, discussing real-life economic struggles within a sitcom format.\",\n",
    "            \"article_id\": 77\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What was the main message Nikki R. Haley conveyed in her first remarks at the United Nations?\",\n",
    "            \"answer\": \"The main message was that the Trump administration would hold to account those who do not back the United States, signaling a change in the way the U.S. interacts with the UN.\",\n",
    "            \"article_id\": 614\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Who is the famed chronicler of the Mao era who finished writing a history of the Cultural Revolution?\",\n",
    "            \"answer\": [\"Yang Jisheng\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What was Yang Jisheng's role during the early phase of the Cultural Revolution?\",\n",
    "            \"answer\": [\"He was a university student in Beijing who immersed himself in the early phase.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is described as 'historical nihilism' by the Chinese government?\",\n",
    "            \"answer\": [\"Delving into events like the Cultural Revolution, described as subversive to corrode the party’s authority.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why did Yang Jisheng decide to write a book about the Cultural Revolution?\",\n",
    "            \"answer\": [\"To expose lies and restore the truth.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why was Yang Jisheng advised not to discuss his book with foreign media after its publication?\",\n",
    "            \"answer\": [\"The article implies there's political pressure, but does not provide a specific reason.\"],\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why do the residents of Monticello, Iowa, appear to have little angst about Donald Trump's presidency?\",\n",
    "            \"answer\": \"Residents seem to have little angst because they perceive that Trump is making changes and influencing Congress, reflecting their desire for political action and change.\",\n",
    "            \"article_id\": 261\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why was Hillary Clinton's visit to Monticello significant during her campaign?\",\n",
    "            \"answer\": \"Hillary Clinton's visit to Monticello was significant because it was her first campaign stop after declaring her candidacy for the Democratic nomination in 2015.\",\n",
    "            \"article_id\": 261\n",
    "        }\n",
    "    ],\n",
    "    \"list_based\": [\n",
    "        {\n",
    "            \"question\": \"List the military activities by China that led to regional tensions, as mentioned in the article.\",\n",
    "            \"answer\": \"Sending the Liaoning through the Taiwan Strait, Chinese bombers and surveillance planes flying over the East China Sea and the Sea of Japan,A Chinese warship seizing a U.S. Navy underwater drone\",\n",
    "            \"article_id\": 239\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Who are the main characters in the Netflix reboot of 'One Day at a Time'?\",\n",
    "            \"answer\": \"Penelope,Alex ,Lydia, Elena\",\n",
    "            \"article_id\": 77\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What are the implications of the Trump administration's stance towards the United Nations as expressed by Nikki R. Haley?\",\n",
    "            \"answer\": \"Holding to account those who do not support the U.S., A potential reduction in U.S. funding for the UN, A focus on showing strength and value in U.N. participation\",\n",
    "            \"article_id\": 614\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Two challenges Yang Jisheng faced while writing his historical works.\",\n",
    "            \"answer\": \"He was warned against publishing his book and barred from traveling to the United States; he was told not to discuss the book with foreign media.\",\n",
    "            \"article_id\": 494\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"The types of jobs held by the men who meet at the Table of Knowledge.\",\n",
    "            \"answer\": \"optometrist, farmers, former employees of a utility company\",\n",
    "            \"article_id\": 261\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"The types of information alleged in the memos about Trump's ties to Russia.\",\n",
    "            \"answer\": \"Blackmail with sex tapes, Bribery with business deals, Meetings with Russian operatives to discuss hacking and leaking emails\",\n",
    "            \"article_id\": 230\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"List some of the initiatives taken by OGC Nice to enhance fan experience at their matches.\",\n",
    "            \"answer\": \"Handing out free tickets to local children, Refitting all V.I.P. areas, some of which remain open until the early hours, Installing an ice rink outside the Allianz Riviera before Christmas\",\n",
    "            \"article_id\": 996\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What are the different ways OGC Nice has tried to draw fans into the stadium?\",\n",
    "            \"answer\": \"Signing high-profile players like Mario Balotelli, Making matches a complete experience with various entertainment options, Promoting a 'popular' style of play\",\n",
    "            \"article_id\": 996\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What accolades have members of the Cowboys' offensive line achieved?\",\n",
    "            \"answer\": \"Three of the starters have been chosen to the Pro Bowl, with Tyron Smith having four selections, Travis Frederick three, and Zack Martin three.\",\n",
    "            \"article_id\": 331\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What are the gifts Ezekiel Elliott gave to his linemen for Christmas?\",\n",
    "            \"answer\": \"John Deere utility vehicles\",\n",
    "            \"article_id\": 331\n",
    "        }\n",
    "\n",
    "    ],  \n",
    "    \"cause_based\": [\n",
    "        {\n",
    "            \"question\": \"What geopolitical implications does the passage of the Liaoning through the Taiwan Strait have for Taiwan and China relations?\",\n",
    "            \"answer\": \"The passage increases uncertainty and tensions, possibly exacerbating existing disputes over sovereignty and territorial integrity, as well as impacting the broader regional security dynamics.\",\n",
    "            \"article_id\": 239\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why did many farmers switch from voting for Obama to Trump?\",\n",
    "            \"answer\": \"Many farmers switched to Trump despite his opposition to the TPP because they voted against what they perceived as their economic interests, possibly influenced by broader political or cultural concerns.\",\n",
    "            \"article_id\": 261\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What concerns did Mike Staudt have about the Affordable Care Act?\",\n",
    "            \"answer\": \"Mike Staudt described the Affordable Care Act as a form of socialism, reflecting his concern about government overreach into healthcare.\",\n",
    "            \"article_id\": 261\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why might American intelligence agencies have not confirmed the claims in the memos about Trump?\",\n",
    "            \"answer\": \"Because the claims were unsubstantiated and based on opposition research that neither intelligence agencies nor news organizations like The New York Times could verify.\",\n",
    "            \"article_id\": 230\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why has OGC Nice been compared to Leicester City?\",\n",
    "            \"answer\": \"OGC Nice has been compared to Leicester City due to their similar stories of being smaller clubs defying financial odds to compete at high levels in their respective leagues.\",\n",
    "            \"article_id\": 996\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How has OGC Nice's approach to building its team differed from the perceived 'wonderful accident' of Leicester City's success?\",\n",
    "            \"answer\": \"Unlike Leicester City's unexpected success, OGC Nice's rise has been strategic and planned, involving steady growth since Jean-Pierre Rivère took control, investment in facilities, and intelligent recruitment.\",\n",
    "            \"article_id\": 996\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"Why is the Cowboys' offensive line considered crucial to their success?\",\n",
    "            \"answer\": \"The line consistently provides strong protection and blocking, which is fundamental for both their running and passing games, supporting the performances of both quarterback Dak Prescott and running back Ezekiel Elliott.\",\n",
    "            \"article_id\": 331\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"How did the Cowboys' management build such a strong offensive line?\",\n",
    "            \"answer\": \"The team focused on strengthening the line by using high draft picks on blockers, selecting Tyron Smith in 2011, Travis Frederick in 2013, and Zack Martin in 2014, which laid the foundation for their current success.\",\n",
    "            \"article_id\": 331\n",
    "        },\n",
    "        {\n",
    "        \"question\": \"Why is Justice Teori Zavascki's death particularly impactful for Brazil's judiciary?\",\n",
    "        \"answer\": \"Justice Zavascki was a key figure in major corruption investigations, including overseeing the plea deal ratification for Odebrecht, which implicated numerous politicians. His death throws the continuation and direction of these high-stakes cases into uncertainty.\",\n",
    "        \"article_id\": 456\n",
    "        },\n",
    "        {\n",
    "        \"question\": \"What concerns are raised by the timing of Justice Zavascki's death?\",\n",
    "        \"answer\": \"The timing of his death is concerning because it coincides with escalating investigations into high-profile corruption cases involving Petrobras and Odebrecht, leading to speculation about potential foul play to disrupt these proceedings.\",\n",
    "        \"article_id\": 456\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "349ed28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_answer_question(query_text, use_relevant_content=True):\n",
    "    # 假设ranked_docs是通过某种方式得到的文档ID列表\n",
    "    ranked_docs = search_documents(query_text)\n",
    "    if not ranked_docs:\n",
    "        return \"No documents found or query format incorrect.\"\n",
    "\n",
    "    # 获取所有相关文档的内容\n",
    "    all_articles = ''\n",
    "    for doc_id in ranked_docs:\n",
    "        # 假设可以通过doc_id获取到文档内容\n",
    "        article = sample_df.loc[doc_id, 'article']\n",
    "        all_articles += article + ' '\n",
    "\n",
    "    # 根据use_relevant_content变量决定使用哪种内容寻找答案\n",
    "    if use_relevant_content:\n",
    "        # 找到与问题最相关的内容片段\n",
    "        top_n_contents = find_top_n_relevant_contents(query_text, all_articles, top_n=3)\n",
    "        relevant_context = ' '.join([content[0] for content in top_n_contents])\n",
    "        context_to_use = relevant_context\n",
    "    else:\n",
    "        # 使用全部内容\n",
    "        context_to_use = all_articles\n",
    "\n",
    "    # 使用选择的内容寻找答案\n",
    "    answer = find_answer(query_text, context_to_use)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7dce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(test_data, qa_system_func, use_relevant_content=True):\n",
    "    f1_scores, mrr_scores, map_scores, rouge_l_scores = [], [], [], []\n",
    "\n",
    "    for items in test_data:\n",
    "        print(f\"Evaluating {items} questions...\")\n",
    "        print(\"\")\n",
    "        # 初始化每个类别的分数列表，以便在每个类别结束时计算平均值\n",
    "        cat_f1_scores, cat_mrr_scores, cat_map_scores, cat_rouge_l_scores = [], [], [], []\n",
    "\n",
    "        for i in test_data[items]:\n",
    "            question, true_answer, true_article_id = i[\"question\"], [i[\"answer\"]], [i[\"article_id\"]]\n",
    "        \n",
    "            predicted_answers_with_scores = qa_system_func(question, use_relevant_content)\n",
    "            \n",
    "            # 假设 search_documents 返回与预测相关的文章ID列表\n",
    "            predicted_article_ids = search_documents(question)\n",
    "            predicted_answers = [ans[0] for ans in predicted_answers_with_scores]\n",
    "            f1 = compute_f1_single(predicted_answers[0], true_answer[0])  # 假设只有一个真实答案和一个预测答案\n",
    "            mrr = compute_mrr(predicted_article_ids, true_article_id)\n",
    "            map_score = compute_map(predicted_article_ids, true_article_id)\n",
    "            rouge_l = compute_rouge_l_multi(predicted_answers, true_answer)\n",
    "\n",
    "            cat_f1_scores.append(f1)\n",
    "            cat_mrr_scores.append(mrr)\n",
    "            cat_map_scores.append(map_score)\n",
    "            cat_rouge_l_scores.append(rouge_l)\n",
    "\n",
    "        # 计算当前类型问题的平均性能指标\n",
    "        avg_f1 = np.mean(cat_f1_scores)\n",
    "        avg_mrr = np.mean(cat_mrr_scores)\n",
    "        avg_map = np.mean(cat_map_scores)\n",
    "        avg_rouge_l = np.mean(cat_rouge_l_scores)\n",
    "\n",
    "        # 打印当前类型问题的平均性能指标\n",
    "        print(f\"Average F1 Score for {items}: {avg_f1:.3f}\")\n",
    "        print(f\"Average MRR for {items}: {avg_mrr:.3f}\")\n",
    "        print(f\"Average MAP for {items}: {avg_map:.3f}\")\n",
    "        print(f\"Average ROUGE-L for {items}: {avg_rouge_l:.3f}\")\n",
    "        print(\"\")  # 打印空行以分隔不同类型的输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37723630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rustl with whole content\n",
      "\n",
      "Evaluating fact_based questions...\n",
      "\n",
      "Average F1 Score for fact_based: 0.629\n",
      "Average MRR for fact_based: 0.850\n",
      "Average MAP for fact_based: 0.850\n",
      "Average ROUGE-L for fact_based: 0.290\n",
      "\n",
      "Evaluating explanation_based questions...\n",
      "\n",
      "Average F1 Score for explanation_based: 0.327\n",
      "Average MRR for explanation_based: 0.900\n",
      "Average MAP for explanation_based: 0.900\n",
      "Average ROUGE-L for explanation_based: 0.169\n",
      "\n",
      "Evaluating list_based questions...\n",
      "\n",
      "Average F1 Score for list_based: 0.174\n",
      "Average MRR for list_based: 0.800\n",
      "Average MAP for list_based: 0.800\n",
      "Average ROUGE-L for list_based: 0.183\n",
      "\n",
      "Evaluating cause_based questions...\n",
      "\n",
      "Average F1 Score for cause_based: 0.065\n",
      "Average MRR for cause_based: 0.833\n",
      "Average MAP for cause_based: 0.833\n",
      "Average ROUGE-L for cause_based: 0.235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Rustl with whole content')\n",
    "print(\"\")\n",
    "run_evaluation(questions_answers, auto_answer_question , use_relevant_content=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8673376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rustl with relevant content\n",
      "\n",
      "Evaluating fact_based questions...\n",
      "\n",
      "Average F1 Score for fact_based: 0.100\n",
      "Average MRR for fact_based: 0.850\n",
      "Average MAP for fact_based: 0.850\n",
      "Average ROUGE-L for fact_based: 0.094\n",
      "\n",
      "Evaluating explanation_based questions...\n",
      "\n",
      "Average F1 Score for explanation_based: 0.164\n",
      "Average MRR for explanation_based: 0.900\n",
      "Average MAP for explanation_based: 0.900\n",
      "Average ROUGE-L for explanation_based: 0.017\n",
      "\n",
      "Evaluating list_based questions...\n",
      "\n",
      "Average F1 Score for list_based: 0.056\n",
      "Average MRR for list_based: 0.800\n",
      "Average MAP for list_based: 0.800\n",
      "Average ROUGE-L for list_based: 0.169\n",
      "\n",
      "Evaluating cause_based questions...\n",
      "\n",
      "Average F1 Score for cause_based: 0.083\n",
      "Average MRR for cause_based: 0.833\n",
      "Average MAP for cause_based: 0.833\n",
      "Average ROUGE-L for cause_based: 0.228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Rustl with relevant content')\n",
    "print(\"\")\n",
    "run_evaluation(questions_answers, auto_answer_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b44c8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_interaction(qa_system_func, use_relevant_content=True):\n",
    "    print(\"Welcome to the QA System!\")\n",
    "    print(\"Type 'exit' to leave the system.\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"Please enter your question: \")\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting the QA system. Goodbye!\")\n",
    "            break  # 退出循环，结束程序\n",
    "\n",
    "        # 可以在这里添加更多的逻辑来处理用户输入，比如清洗和预处理\n",
    "        # 假设 search_documents 返回与预测相关的文章ID\n",
    "        predicted_article_ids = search_documents(question)\n",
    "\n",
    "        if not predicted_article_ids:\n",
    "            print(\"No relevant documents found. Try another question.\")\n",
    "            continue\n",
    "\n",
    "        # 获取所有相关文档的内容并选择内容\n",
    "        all_articles = ''\n",
    "        for doc_id in predicted_article_ids:\n",
    "            article = sample_df.loc[doc_id, 'article']  # 假设可以通过doc_id获取到文档内容\n",
    "            all_articles += article + ' '\n",
    "\n",
    "        # 根据设置决定使用哪种内容寻找答案\n",
    "        if use_relevant_content:\n",
    "            # 找到与问题最相关的内容片段\n",
    "            top_n_contents = find_top_n_relevant_contents(question, all_articles, top_n=3)\n",
    "            relevant_context = ' '.join([content[0] for content in top_n_contents])\n",
    "            context_to_use = relevant_context\n",
    "        else:\n",
    "            # 使用全部内容\n",
    "            context_to_use = all_articles\n",
    "\n",
    "        # 使用选择的内容寻找答案\n",
    "        answers = find_answer(question, context_to_use)\n",
    "        print(\"Answer(s):\")\n",
    "        for answer, score in answers:\n",
    "            print(f\"- {answer} (confidence: {score:.2f})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_answer_question(query_text, use_relevant_content=True):\n",
    "    # 假设ranked_docs是通过某种方式得到的文档ID列表\n",
    "    ranked_docs = search_documents(query_text)\n",
    "    if not ranked_docs:\n",
    "        return \"No documents found or query format incorrect.\"\n",
    "\n",
    "    # 获取所有相关文档的内容\n",
    "    all_articles = ''\n",
    "    for doc_id in ranked_docs:\n",
    "        # 假设可以通过doc_id获取到文档内容\n",
    "        article = sample_df.loc[doc_id, 'article']\n",
    "        all_articles += article + ' '\n",
    "\n",
    "    # 根据use_relevant_content变量决定使用哪种内容寻找答案\n",
    "    if use_relevant_content:\n",
    "        # 找到与问题最相关的内容片段\n",
    "        top_n_contents = find_top_n_relevant_contents(query_text, all_articles, top_n=3)\n",
    "        relevant_context = ' '.join([content[0] for content in top_n_contents])\n",
    "        context_to_use = relevant_context\n",
    "    else:\n",
    "        # 使用全部内容\n",
    "        context_to_use = all_articles\n",
    "\n",
    "    # 使用选择的内容寻找答案\n",
    "    answer = find_answer(query_text, context_to_use)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8be7532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the QA System!\n",
      "Type 'exit' to leave the system.\n",
      "Answer(s):\n",
      "- mr. trump has said they are a complete fabrication (confidence: 0.58)\n",
      "- they are a complete fabrication (confidence: 0.52)\n",
      "- trump has said they are a complete fabrication (confidence: 0.48)\n",
      "Exiting the QA system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# 调用用户交互函数\n",
    "user_interaction(auto_answer_question,use_relevant_content = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3a91b4",
   "metadata": {},
   "source": [
    "## B. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7553c1",
   "metadata": {},
   "source": [
    "## C. Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
